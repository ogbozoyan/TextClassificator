# TextClassificator

##ВВЕДЕНИЕ
Целью данной работы является разработка приложения для классификации текста и файлов. 
Было решено сделать веб-приложение на основе микро-сервисной архитектуры, где приложение будет делиться на три части backend, frontend и сервер классификации.
Преимущество такого подхода - независимость пользователя от операционной системы. Пользователь сможет пользоваться приложением на любом устройстве, где есть веб-браузер.
Для backend части был использован фреймворк Spring Framework, основанный на языке Java. Также для хранения обработанных данных используется реляционная база данных MySQL.
Frontend часть - это React приложение, использующее restful api, которое предоставляет spring приложение.
Сервер классификации используется для классификации текста. Он делится на две части: сам сервер для общения с spring приложением, и классификатор, построенный на библиотеке scikit-learn.




##ГЛАВА 1
##Задачи, которые решает приложение.
###Backend.
Spring Framework обеспечивает комплексную модель разработки и конфигурации для современных бизнес-приложений на Java - на любых платформах. Ключевой элемент Spring - поддержка инфраструктуры на уровне приложения: основное внимание уделяется "водопроводу" бизнес-приложений, поэтому разработчики могут сосредоточиться на бизнес-логике без лишних настроек в зависимости от среды исполнения.
Spring Boot — это полезный проект, целью которого является упрощение создания приложений на основе Spring. Он позволяет наиболее простым способом создать web-приложение, требуя от разработчиков минимум усилий по его настройке и написанию кода.
Spring Boot обладает большим функционалом, но его наиболее значимыми особенностями являются: управление зависимостями, автоматическая конфигурация и встроенные контейнеры сервлетов. Превосходной возможностью Spring Boot является автоматическая конфигурация приложения.
Также в “бэке” используется библиотека Apache Tika версии 1.12, c помощью которой достаются метаданные из файлов. Apache Tika - это кроссплатформенный набор инструментов, написанный на Java для предварительной обработки и анализа текстовой информации - выделения метаданных, извлечения текста из разнообразных форматов файлов, автоматического определения языка текста и т.п.
Реляционная база данных (SQL) — база, где данные хранятся в формате таблиц, они строго структурированы и связаны друг с другом. В таблице есть строки и столбцы, каждая строка представляет отдельную запись, а столбец — поле с назначенным ей типом данных. В каждой ячейке информация записана по шаблону.
Frontend.
Fronted приложение построено на JavaScript библиотеке React. Это open source библиотека для разработки пользовательских интерфейсов. Чаще всего используется для построения SPA (Single-page application) и мобильных приложений. 
SPA - веб-приложение, использующее единственный html-документ как оболочка для всех веб-страниц и организующий взаимодействие с пользователем через динамически подгружаемые HTML, CSS, JavaScript, посредством асинхронных запросов к серверу.
Разработанное в ходе выполнения задания react-приложение реализует понятный пользователю UI с возможностью загрузки файла или текста, который должен быть классифицирован, отправка его на сервер, и получение результата классификации.
Классификатор.
В машинном обучении под классификацией понимают задачу определения категории, к которой принадлежит ранее не встречавшийся образец, на основании обучающего множества, для элементов которого эти категории известны. Это является примером обучения с учителем (supervised learning). 
Существует множество подходов к классификации: деревья принятия решений, нейронные сети, вероятностные методы и т.д.. В данной работе было решено использовать Наивный Байесовский классификатор из-за легкости реализации и точности классифицирования текста, который предоставляет этот метод.
Наивный Байесовский классификатор - это вероятностная модель машинного обучения, которая используется для задачи классификации. Суть классификатора основана на теореме Байеса.
Python библиотека scikit-learn предоставляет методы для машинного обучения. В проекте будет использоваться мультиномиальный наивный Байес:
 sklearn.naive_bayes.MultinomialNB
Предполагается, что для этого метода классификации признаки взяты из простого мультиномиального распределения. 
Именно этот метод был использован при проектировании модели обучения, так как он больше всего подходит для классификации текстов по категориям.
Метод MultinomialNB из библиотеки scikit-learn реализует наивный байесовский алгоритм для полиномиально распределенных данных и является одним из двух классических наивных байесовских вариантов, используемых в классификации текста (где данные обычно представлены как счетчики векторов слов).

##ГЛАВА 2
##Обзор работы модулей.
###Backend.

Для настройки и запуска Spring Boot приложений требуется следующее:
Java 8+
Apache Maven 3. x
Maven — инструмент для автоматизации сборки проектов. С ним работают в основном Java-разработчики, хотя есть плагины для интеграции с C/C++, Ruby, Scala, PHP и другими языками. 
Конфигурация проекта проекта происходит в pom.xml, который выстраивает архетип, а также подтягивает все необходимые зависимости.
 
        ###Что происходит под капотом? 
Основной концепций является REST API. Spring приложение обрабатывает либо текст, либо файл(в зависимости от выбора юзера) и обращается к классификатору находящийся в одной сети с Spring приложением. Все общение между разными сервисами происходит через JSON файлы которые летают по сети(передаются по протоколу HTTP)
Spring принимает на вход со стороны Frontend JSON:

POST "{c_token}/upload/text"
"Content-Type": "application/json"
JSON:
{
 "payload":string
}


POST "{c_token}/upload/file"
"Content-Type": "multipart/form-data"
JSON:
{
 "payload": file
}

После принятия данных Spring приложение в зависимости от типа запроса начинает обрабатывать данные, в случай просто текста, пропускается часть с получением метаданных. В случае с файлом на вход вызываются следующий алгоритм действий:

1. Объявляется объект класса fileController,где в конструкторе класса идет инициализация объектов из Apache Tika.
Parser parser = new AutoDetectParser();
BodyContentHandler handler = new BodyContentHandler(-1);
Metadata metadata = new Metadata();
ParseContext context = new ParseContext();

 Достаем метаданные:
parser.parse(stream, handler, metadata, context);


2. Формируется JSON которые потом передается в классификатор:

new HttpPost("http://127.0.0.1:5000/");
request.addHeader("content-type", "application/json");
request.setEntity(
            new HashMap<> (
                                          "id": longint,
                                          "text": string,
                                          "size",int        )     );


3. Получаем ответ от классификатора в JSON и отправляем на Фронт результат классификации:
{
   "id":int,
   "result": string
}

4.Сохраняем в БД в таблицу Data:
fname,size,text

 Модель:
@Entity
public class Data {
    @Id
    @GeneratedValue(strategy = GenerationType.AUTO)
    private long id;
    private String fname;
    private String text;
    private String size;

    public long getId() {
        return id;
    }

    public void setId(long id) {
        this.id = id;
    }

    public String getFname() {
        return fname;
    }

    public void setFname(String fname) {
        this.fname = fname;
    }

    public String getText() {
        return text;
    }

    public void setText(String text) {
        this.text = text;
    }

    public String getSize() {
        return size;
    }

    public void setSize(String size) {
        this.size = size;
    }
}

Мерой безопасностью было принято решение использовать заранее оговоренный токен, который можно выдать доверенным лицам и мапинг  происходит благодаря этому токену. Запросы делаются {c_token}/upload/{type}, где c_token - токен который задается пользователем со стороны фронта, в случае если токен подходящий,то запросы будут приходить по верному адресу соответственно и работать будет все как положено; type - тип данных: file либо text. 
GET запрос по адресу /data возвращает все записи из БД. 
В качестве веб сервера для Spring приложения использовали tomcat. Для удобного пользования БД установлен phpmyadmin.
Путь по которому сохраняются файлы: 
private final static String FOLDER = "files/";


###Frontend.
В React-приложении пользователю доступна форма для загрузки файла и текстовое поля. После загрузки происходит отправка на сервер и ожидание результатов. После того, как результаты были получены, он отображаются пользователю. Для общения с сервером была написана функция uploadData, которая отправляет и принимает данные.
function uploadData(event) {
    event.preventDefault();
    let data = {};
    let headers = {};

    if (type === "text") {
      data = {
        payload: payload,
      };
      data = JSON.stringify(data);
      headers = {
        "Content-Type": "application/json",
      };
    }

    if (type === "file") {
      data = new FormData();
      data.append("file", payload);
    }

 fetch(`http://172.20.10.7:8080/${token}/upload/${type}/`, {
      method: "POST",
      headers: headers,
      body: data,
    })
      .then((response) => {
        return response.json();
      })
      .then((response) => {
        dispatch({
          type: "SET_RESULT",
          payload: [response.id, response.result],
        });
      })
      .catch((err) => {
        dispatch({
          type: "SET_ERROR",
          payload: [“error”, err],
        });
      });
  }

###Классификатор.
Для обучения модели необходимо найти выборку данных. За основу был выбрано 1500 статей, взятых с различных сайтов, классифицированных на основе своего содержания. JSON с именами категорий и количество статей, относящиеся к этим категориям представлен ниже: 
{
   "Travel":106,
   "Social Networking and Messaging":79,
   "News":92,
   "Streaming Services":104,
   "Sports":100,
   "Photography":87,
   "Law and Government":83,
   "Health and Fitness":89,
   "Games":98,
   "E-Commerce":101,
   "Forums":16,
   "Food":92,
   "Education":114,
   "Computers and Technology":90,
   "Business/Corporate":108,
   "Adult":16 
}

Далее данные очищаются от слов-паразитов и повторяющихся слов и подготавливаются к загрузке в модель для обучения.
Подготовка данных, обучение, сохранение.
Класс NaiveBayesClassification содержит методы для получения данных, для тренировки, и для сохранения натренированной модели для дальнейшего использования.
Подготовим данные для обучения: 
>>> from classifier import NaiveBayesClassification
>>> classifier = NaiveBayesClassification()
>>> classifier.get_train_data()
[!] data prepaired

После того, как данные были подготовлены, начнем тренировку модели:
>>> classifier.train()
[i] train score: 0.980909090909091
[i] test score: 0.88
[i] confusion matrix: 
[[ 1  0  0  1  0  0  0  0  0  0  3  0  0  0  0  0]
 [ 0 12  0  1  1  0  0  0  0  1  2  2  0  0  0  0]
 [ 0  0 11  0  1  0  0  0  0  0  0  1  0  0  0  0]
 [ 0  0  0 25  0  0  0  0  1  0  0  0  0  0  0  0]
 [ 0  1  0  0 20  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0 25  0  0  0  0  0  0  0  0  0  1]
 [ 0  0  0  0  0  0  0  0  0  0  1  1  0  0  1  0]
 [ 0  0  0  0  0  0  0 15  0  0  0  0  0  1  1  0]
 [ 0  0  0  0  0  0  0  0 15  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0 24  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 18  0  0  1  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  1 15  0  0  0  0]
 [ 0  0  1  0  1  1  0  1  0  0  0  0  6  0  1  1]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0]
 [ 0  0  1  0  0  0  0  0  0  0  1  0  0  0 14  0]
 [ 0  0  0  0  0  0  1  0  0  0  1  0  0  0  0 19]]

Матрица ошибок (confusion matrix) - представляет собой особый макет таблицы, который позволяет визуализировать производительность алгоритма.
Далее сохраним натренированную модель:
>>> classifier.save_model('../trained_model')
[!] saved

###Классификация текста.
Класс PrepareModel содержит метод для загрузки сохраненной модели и метод для классификации текста.
Импортируем класс, загрузим модель и попробуем классифицировать несколько предложений:
>>> from classifier import PrepareModel
>>> classifier = PrepareModel('finalized_model.sav')
>>>
>>> print( classifier.predict('Manjaro is a Linux based alternative operating system') )
Computers and Technology

>>> print( classifier.predict('It is 20 years since Brazil won the World Cup') 
Sports

###Сервер классификации.
Для общения со Spring приложением был сделан простой сервер, основанный на микро-фреймворке python-flask, который принимает от Spring приложения данные для классификации в формате JSON и возвращает обратно JSON с результатом классификации:  
model = PrepareModel('finalized_model.sav')

@app.route('/', methods=['GET'])
def main():
    try:
        request_data = request.get_json()
    except:
        return jsonify({
            'ok': False,
            'result': '400 Bad Request',
        })
    querry_id = request_data.get('id')
    text = request_data.get('text')
    if querry_id is None or text is None:
        return {
            'ok': False,
            'result': '400 Bad Request',
        }

    try:
        predict = model.predict(text)
    except:
        return {
            'ok': False,
            'result': '500 Internal Error',
        }

    return {
        'id': querry_id,
        'result': predict,
    }


##ЗАКЛЮЧЕНИЕ
Нами было разработано комплексное, большое приложение, объединяющее в себе совершенно разные технологии. Мы получили бесценный опыт в разработке веб-приложений,  и он, безусловно, пригодится нам в будущем.


#Docker compose


version: '3.7'

services:
  spring-boot:
    ports:
      - 8080:8080
    volumes:
      - ./spring:/app
    build: spring/
    networks:
      - app
    depends_on:
      - "mysql"
    

  python-flask:
    image: python:latest
    ports:
      - 5001:5000
    volumes:
      - ./python/python:/app
    build: python/
    networks:
      - app

  mysql:
    platform: linux/x86_64
    image: mysql:5.7
    ports:
      - 8889:8889
    environment:
      - MYSQL_ROOT_PASSWORD=root
      - MYSQL_DATABASE=Database
      - MYSQL_USER=user
      - MYSQL_PASSWORD=root
    networks:
      - app

  phpmyadmin:
    image: phpmyadmin/phpmyadmin
    ports:
      - 8888:80
    environment:
      - PMA_HOST=mysql
      - PMA_USER=root
      - PMA_PASSWORD=root
    networks:
      - app
    depends_on:
      - "mysql"

networks:
  app: {}
